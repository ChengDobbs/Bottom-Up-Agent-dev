import chromadb
import torch
import clip
import cv2
import numpy as np
from PIL import Image
import json
import pickle
import hashlib
from datetime import datetime
from typing import List, Dict, Optional, Tuple
import os
import logging
from chromadb.utils.embedding_functions import known_embedding_functions
from chromadb import Documents, EmbeddingFunction, Embeddings

class VectorMemory:
    """
    åŸºäºChromaå‘é‡æ•°æ®åº“çš„å¯¹è±¡å­˜å‚¨å’Œæ£€ç´¢ç³»ç»Ÿ
    æ”¯æŒå›¾åƒå‘é‡åŒ–ã€ç›¸ä¼¼åº¦åŒ¹é…å’Œæ™ºèƒ½å»é‡
    """
    
    def __init__(self, config):
        # æ—¥å¿—é…ç½® - é¦–å…ˆåˆå§‹åŒ–
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        self.game_name = config['game_name']
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # åˆå§‹åŒ–CLIPæ¨¡å‹ç”¨äºå›¾åƒç¼–ç 
        self.clip_model, self.clip_preprocess = clip.load("ViT-B/32", device=self.device)
        
        # å‘é‡æ•°æ®åº“é…ç½® - æ ‡å‡†åŒ–è·¯å¾„
        game_name_normalized = self.game_name.lower().replace(" ", "_")
        self.vector_db_path = os.path.join(config.get('database', {}).get('vector_db_path', os.path.join('data', 'vector')), game_name_normalized)

        self.similarity_threshold = config.get('vector_memory', {}).get('similarity_threshold', 0.5)
        self.vector_dim = 512  # CLIP ViT-B/32 è¾“å‡ºç»´åº¦
        
        # è·å–é…ç½®ä¸­çš„embedding_type
        self.embedding_type = config.get('vector_memory', {}).get('embedding_type', None)
        
        # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(path=self.vector_db_path)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç©ºæ•°æ®åº“
        clear_on_init = config.get('vector_memory', {}).get('clear_on_init', False)
        if clear_on_init:
            self.logger.info("CLEARING VECTOR DATABASE AS CONFIGURED")
            self.clear_database()
        
        # åˆå§‹åŒ–Chromaæ•°æ®åº“ - get_or_create_collectionä¼šè‡ªåŠ¨å¤„ç†åˆ›å»ºé€»è¾‘
        self._init_chroma_db()
        
    def _init_chroma_db(self):
        """åˆå§‹åŒ–Chromaå‘é‡æ•°æ®åº“"""
        try:
            # å¤„ç†embedding_typeé…ç½®
            if not self.embedding_type or self.embedding_type == "":
                # ç©ºå­—ç¬¦ä¸²æˆ–Noneï¼Œä½¿ç”¨é»˜è®¤embedding
                print(f"Use default embedding in the vector database as {self.embedding_type}.")
                # åˆ›å»ºæŒä¹…åŒ–å®¢æˆ·ç«¯
                self.object_collection = self.client.get_or_create_collection(
                    name="ui_objects",
                    metadata={"hnsw:space": "cosine"}
                )
            elif self.embedding_type == "CLIP":
                # ä½¿ç”¨ç°æˆçš„CLIPç¼–ç æ–¹æ³•
                print(f"Use CLIP embedding with custom encode/decode methods.")
                self.object_collection = self.client.get_or_create_collection(
                    embedding_function=CLIPEmbeddingFunction(),
                    name="ui_objects",
                    metadata={"hnsw:space": "cosine"}
                )
            elif self.embedding_type in known_embedding_functions:
                # ä½¿ç”¨known_embedding_functionsä¸­çš„embedding
                print(f"Use {self.embedding_type} to embed in the vector database.")
                try:
                    # å®ä¾‹åŒ–embeddingå‡½æ•°
                    embedding_function = known_embedding_functions[self.embedding_type]()
                    self.object_collection = self.client.get_or_create_collection(
                        name="ui_objects",
                        embedding_function=embedding_function,
                        metadata={"hnsw:space": "cosine"}
                    )
                except Exception as e:
                    self.logger.error(f"Failed to use embedding_type '{self.embedding_type}': {e}")
                    self.logger.info("Falling back to default embedding.")
                    self.object_collection = self.client.get_or_create_collection(
                        name="ui_objects",
                        metadata={"hnsw:space": "cosine"}
                    )
            else:
                # ä¸æ”¯æŒçš„embedding_typeï¼Œä½¿ç”¨é»˜è®¤
                self.logger.warning(f"Unsupported embedding_type '{self.embedding_type}', using default embedding.")
                self.object_collection = self.client.get_or_create_collection(
                    name="ui_objects",
                    metadata={"hnsw:space": "cosine"}
                )
            
            self.logger.info(f"CHROMA DB INITIALIZED: {self.vector_db_path}")
            
        except Exception as e:
            self.logger.error(f"CHROMA DB INITIALIZATION FAILED: {e}")
            raise
    
    def encode_image(self, image: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨CLIPæ¨¡å‹å¯¹å›¾åƒè¿›è¡Œå‘é‡ç¼–ç 
        
        Args:
            image: OpenCVæ ¼å¼çš„å›¾åƒ (BGR)
            
        Returns:
            å½’ä¸€åŒ–çš„å›¾åƒç‰¹å¾å‘é‡
        """
        try:
            # è½¬æ¢ä¸ºPILå›¾åƒ (RGB)
            if len(image.shape) == 3:
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            else:
                image_rgb = image
                
            pil_image = Image.fromarray(image_rgb)
            
            # é¢„å¤„ç†å¹¶ç¼–ç 
            image_input = self.clip_preprocess(pil_image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                image_features = self.clip_model.encode_image(image_input)
                # å½’ä¸€åŒ–å‘é‡
                image_features = image_features / image_features.norm(dim=-1, keepdim=True)
                
            return image_features.cpu().numpy().flatten()
            
        except Exception as e:
            self.logger.error(f"IMAGE ENCODING FAILED: {e}")
            return np.zeros(self.vector_dim)
    
    def encode_text(self, text: str) -> np.ndarray:
        """
        ä½¿ç”¨CLIPæ¨¡å‹å¯¹æ–‡æœ¬è¿›è¡Œå‘é‡ç¼–ç 
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            å½’ä¸€åŒ–çš„æ–‡æœ¬ç‰¹å¾å‘é‡
        """
        try:
            # å¯¹æ–‡æœ¬è¿›è¡Œtokenize
            text_input = clip.tokenize([text]).to(self.device)
            
            with torch.no_grad():
                text_features = self.clip_model.encode_text(text_input)
                # å½’ä¸€åŒ–å‘é‡
                text_features = text_features / text_features.norm(dim=-1, keepdim=True)
                
            return text_features.cpu().numpy().flatten()
            
        except Exception as e:
            self.logger.error(f"TEXT ENCODING FAILED: {e}")
            return np.zeros(self.vector_dim)
    
    def _preprocess_object_image(self, image: np.ndarray, target_size: Tuple[int, int] = (224, 224)) -> np.ndarray:
        """
        æ ‡å‡†åŒ–å¯¹è±¡å›¾åƒ
        
        Args:
            image: åŸå§‹å›¾åƒ
            target_size: ç›®æ ‡å°ºå¯¸
            
        Returns:
            é¢„å¤„ç†åçš„å›¾åƒ
        """
        # è°ƒæ•´å¤§å°
        resized = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)
        
        # ç¡®ä¿æ˜¯3é€šé“
        if len(resized.shape) == 2:
            resized = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)
        elif resized.shape[2] == 4:
            resized = cv2.cvtColor(resized, cv2.COLOR_BGRA2BGR)
            
        return resized
    
    def _generate_object_hash(self, obj: Dict) -> str:
        """
        ç”Ÿæˆå¯¹è±¡çš„å”¯ä¸€å“ˆå¸Œå€¼
        
        Args:
            obj: å¯¹è±¡å­—å…¸
            
        Returns:
            å“ˆå¸Œå­—ç¬¦ä¸²
        """
        # ä½¿ç”¨bboxã€contentå’Œå›¾åƒhashç”Ÿæˆå”¯ä¸€æ ‡è¯†
        hash_data = {
            'bbox': obj['bbox'],
            'content': obj.get('content', ''),
            'area': obj['area'],
            'image_hash': obj.get('hash', '')
        }
        
        hash_str = json.dumps(hash_data, sort_keys=True)
        return hashlib.md5(hash_str.encode()).hexdigest()
    
    def store_object(self, obj: Dict) -> str:
        """
        å­˜å‚¨å•ä¸ªå¯¹è±¡åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            obj: åŒ…å«imageã€bboxã€contentç­‰ä¿¡æ¯çš„å¯¹è±¡å­—å…¸
            
        Returns:
            å­˜å‚¨çš„å¯¹è±¡ID
        """
        try:
            obj_type = obj.get('type', 'None')
            
            # æ ¹æ®å¯¹è±¡ç±»å‹é€‰æ‹©ä¸åŒçš„embeddingæ–¹å¼
            if obj_type == 'icon':
                # å¯¹äºiconç±»å‹ï¼Œä½¿ç”¨croppedå›¾åƒçš„embedding
                processed_image = self._preprocess_object_image(obj['image'])
                embedding_vector = self.encode_image(processed_image)
            elif obj_type == 'text':
                # å¯¹äºtextç±»å‹ï¼Œä½¿ç”¨contentçš„æ–‡æœ¬embedding
                content = obj.get('content', '')
                if content:
                    embedding_vector = self.encode_text(content)
                else:
                    # å¦‚æœæ²¡æœ‰contentï¼Œå›é€€åˆ°å›¾åƒembedding
                    processed_image = self._preprocess_object_image(obj['image'])
                    embedding_vector = self.encode_image(processed_image)
            else:
                # å…¶ä»–ç±»å‹é»˜è®¤ä½¿ç”¨å›¾åƒembedding
                processed_image = self._preprocess_object_image(obj['image'])
                embedding_vector = self.encode_image(processed_image)
            
            # ç”Ÿæˆå”¯ä¸€ID
            object_hash = self._generate_object_hash(obj)
            object_id = f"obj_{obj_type}_{object_hash[:8]}"
            
            # å‡†å¤‡å…ƒæ•°æ®
            metadata = {
                'object_id': str(obj.get('id', '')),
                'bbox': json.dumps(obj['bbox']),
                'area': obj['area'],
                'hash': obj.get('hash', ''),
                'center': json.dumps(obj.get('center', [0, 0])),
                'type': obj_type,
                'timestamp': datetime.now().isoformat(),
                'embedding_type': 'image' if obj_type == 'icon' or (obj_type == 'text' and not obj.get('content', '')) else 'text' if obj_type == 'text' else 'image'
            }
            
            # add embedding, content, metadatas to Chroma
            self.object_collection.add(
                embeddings=[embedding_vector.tolist()],
                documents=[obj.get('content', '')],
                metadatas=[metadata],
                ids=[object_id]
            )
            
            self.logger.info(f"OBJECT STORED: {object_id}")
            return object_id
            
        except Exception as e:
            self.logger.error(f"OBJECT STORAGE FAILED: {e}")
            return ""
    
    def batch_store_objects(self, objects: List[Dict]) -> List[str]:
        """
        æ‰¹é‡å­˜å‚¨å¯¹è±¡
        
        Args:
            objects: å¯¹è±¡åˆ—è¡¨
            
        Returns:
            å­˜å‚¨çš„å¯¹è±¡IDåˆ—è¡¨
        """
        if not objects:
            return []
            
        try:
            embeddings = []
            documents = []
            metadatas = []
            ids = []
            
            for obj in objects:
                obj_type = obj.get('type', 'None')
                
                # æ ¹æ®å¯¹è±¡ç±»å‹é€‰æ‹©ä¸åŒçš„embeddingæ–¹å¼
                if obj_type == 'icon':
                    # å¯¹äºiconç±»å‹ï¼Œä½¿ç”¨croppedå›¾åƒçš„embedding
                    processed_image = self._preprocess_object_image(obj['image'])
                    embedding_vector = self.encode_image(processed_image)
                elif obj_type == 'text':
                    # å¯¹äºtextç±»å‹ï¼Œä½¿ç”¨contentçš„æ–‡æœ¬embedding
                    content = obj.get('content', '')
                    if content:
                        embedding_vector = self.encode_text(content)
                    else:
                        # å¦‚æœæ²¡æœ‰contentï¼Œå›é€€åˆ°å›¾åƒembedding
                        processed_image = self._preprocess_object_image(obj['image'])
                        embedding_vector = self.encode_image(processed_image)
                else:
                    # å…¶ä»–ç±»å‹é»˜è®¤ä½¿ç”¨å›¾åƒembedding
                    processed_image = self._preprocess_object_image(obj['image'])
                    embedding_vector = self.encode_image(processed_image)
                
                # ç”ŸæˆIDå’Œå…ƒæ•°æ®
                object_hash = self._generate_object_hash(obj)
                object_id = f"obj_{obj_type}_{object_hash[:8]}"
                
                metadata = {
                    'object_id': str(obj.get('id', '')),
                    'bbox': json.dumps(obj['bbox']),
                    'area': obj['area'],
                    'hash': obj.get('hash', ''),
                    'center': json.dumps(obj.get('center', [0, 0])),
                    'type': obj_type,
                    'timestamp': datetime.now().isoformat(),
                    'embedding_type': 'image' if obj_type == 'icon' or (obj_type == 'text' and not obj.get('content', '')) else 'text' if obj_type == 'text' else 'image'
                }
                
                embeddings.append(embedding_vector.tolist())
                documents.append(obj.get('content', ''))
                metadatas.append(metadata)
                ids.append(object_id)
            
            # æ‰¹é‡å­˜å‚¨
            self.object_collection.add(
                embeddings=embeddings,
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            
            self.logger.info(f"BATCH STORAGE COMPLETED: {len(objects)} objects")
            return ids
            
        except Exception as e:
            self.logger.error(f"BATCH STORAGE FAILED: {e}")
            return []
    
    def find_similar_objects(self, query_obj: Dict, threshold: float = None, top_k: int = 5, embedding_type="default") -> List[Dict]:
        """
        æŸ¥æ‰¾ç›¸ä¼¼çš„å¯¹è±¡
        
        Args:
            query_obj: æŸ¥è¯¢å¯¹è±¡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            
        Returns:
            ç›¸ä¼¼å¯¹è±¡åˆ—è¡¨ï¼ŒæŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
        """
        if threshold is None:
            threshold = self.similarity_threshold
            
        try:
            # ç¼–ç æŸ¥è¯¢å›¾åƒ
            if embedding_type == "CLIP" or (self.embedding_type == "CLIP"):
                # ä½¿ç”¨CLIPè‡ªå®šä¹‰ç¼–ç æ–¹æ³•
                processed_image = self._preprocess_object_image(query_obj['image'])
                query_vector = self.encode_image(processed_image)
                
                # åœ¨Chromaä¸­æœç´¢
                results = self.object_collection.query(
                    query_embeddings=[query_vector.tolist()],
                    n_results=top_k,
                    include=['embeddings', 'documents', 'metadatas', 'distances']
                )
            elif embedding_type in known_embedding_functions:
                # ä½¿ç”¨known_embedding_functionsä¸­çš„embedding
                processed_image = self._preprocess_object_image(query_obj['image'])
                query_vector = self.encode_image(processed_image)
                
                # åœ¨Chromaä¸­æœç´¢
                results = self.object_collection.query(
                    query_embeddings=[query_vector.tolist()],
                    n_results=top_k,
                    include=['embeddings', 'documents', 'metadatas', 'distances']
                )
            else:
                # ä½¿ç”¨é»˜è®¤çš„æ–‡æœ¬æœç´¢
                results = self.object_collection.query(
                    query_texts=[query_obj.get('content', '')],
                    n_results=top_k,
                    include=['embeddings', 'documents', 'metadatas', 'distances']
                )
            
            # å¤„ç†ç»“æœ
            similar_objects = []
            if results['distances'] and results['distances'][0]:
                for i, distance in enumerate(results['distances'][0]):
                    similarity = 1 - distance  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                    if similarity >= threshold:
                        metadata = results['metadatas'][0][i]
                        similar_objects.append({
                            'id': results['ids'][0][i],
                            'similarity': similarity,
                            'content': results['documents'][0][i],
                            'bbox': json.loads(metadata['bbox']),
                            'area': metadata['area'],
                            'center': json.loads(metadata['center']),
                            'type': metadata['type'],
                            'object_id': metadata['object_id'],
                            'timestamp': metadata['timestamp']
                        })
            
            return similar_objects
            
        except Exception as e:
            self.logger.error(f"SIMILARITY SEARCH FAILED: {e}")
            return []
    
    def deduplicate_objects(self, objects: List[Dict], threshold: float = None, 
                           text_weight: float = 0.3, image_weight: float = 0.5, 
                           bbox_weight: float = 0.2) -> Tuple[List[Dict], List[Dict]]:
        """
        å¯¹è±¡å»é‡å¤„ç†ï¼Œä½¿ç”¨ä¼˜åŒ–çš„æ··åˆç›¸ä¼¼æ€§æ£€æµ‹
        ä¼˜åŒ–ç­–ç•¥ï¼š
        1. ä½¿ç”¨æ›´å…¨é¢çš„å€™é€‰å¯¹è±¡é›†åˆ
        2. é‡‡ç”¨å¤šé˜¶æ®µç›¸ä¼¼æ€§æ£€æµ‹
        3. é’ˆå¯¹å»é‡åœºæ™¯è°ƒæ•´æƒé‡å’Œé˜ˆå€¼
        
        Args:
            objects: å¾…å¤„ç†çš„å¯¹è±¡åˆ—è¡¨
            threshold: å»é‡é˜ˆå€¼
            text_weight: æ–‡æœ¬ç›¸ä¼¼æ€§æƒé‡
            image_weight: å›¾åƒç›¸ä¼¼æ€§æƒé‡
            bbox_weight: è¾¹ç•Œæ¡†ç›¸ä¼¼æ€§æƒé‡
            
        Returns:
            (æ–°å¯¹è±¡åˆ—è¡¨, é‡å¤å¯¹è±¡åˆ—è¡¨)
        """
        if threshold is None:
            threshold = self.similarity_threshold
            
        new_objects = []
        duplicate_objects = []
        
        collection_count = self.object_collection.count()
        database_is_empty = collection_count == 0
        
        if database_is_empty:
            self.logger.info("DATABASE IS EMPTY - Skipping database deduplication, only checking batch duplicates")
        
        # ä¸ºæ¯ä¸ªå¯¹è±¡ç”Ÿæˆhashä»¥æé«˜æ¯”è¾ƒæ•ˆç‡
        for obj in objects:
            if 'hash' not in obj or not obj['hash']:
                obj['hash'] = self._generate_object_hash(obj)
        
        for i, obj in enumerate(objects):
            # é¦–å…ˆè¿›è¡Œå¿«é€Ÿhashæ¯”è¾ƒ
            found_duplicate = False
            
            # é˜¶æ®µ1a: åœ¨å·²å¤„ç†çš„æ–°å¯¹è±¡ä¸­æŸ¥æ‰¾å®Œå…¨ç›¸åŒçš„hashï¼ˆæ‰¹æ¬¡å†…å»é‡ï¼‰
            for existing_obj in new_objects:
                if (obj.get('hash') and existing_obj.get('hash') and 
                    obj['hash'] == existing_obj['hash']):
                    duplicate_objects.append({
                        'original': obj,
                        'similar': existing_obj,
                        'similarity': 1.0,
                        'reason': 'identical_hash_batch'
                    })
                    print(f"ğŸ”„ DUPLICATE DETECTED (Hash-Batch): {obj.get('content', 'Unknown')} (Sim: 1.000)")
                    found_duplicate = True
                    break
            
            if found_duplicate:
                continue
                
            # é˜¶æ®µ1b: åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾å®Œå…¨ç›¸åŒçš„hashï¼ˆä¸å·²å­˜å‚¨å¯¹è±¡å»é‡ï¼‰
            if not database_is_empty and obj.get('hash'):
                try:
                    # ç›´æ¥ä½¿ç”¨whereæ¡ä»¶æŸ¥æ‰¾ç›¸åŒhashçš„å¯¹è±¡
                    hash_results = self.object_collection.get(
                        where={"hash": obj['hash']},
                        include=['metadatas', 'documents']
                    )
                    
                    # å¦‚æœæ‰¾åˆ°ç›¸åŒhashçš„å¯¹è±¡
                    if hash_results['ids'] and len(hash_results['ids']) > 0:
                        # å–ç¬¬ä¸€ä¸ªåŒ¹é…çš„å¯¹è±¡
                        matched_id = hash_results['ids'][0]
                        matched_metadata = hash_results['metadatas'][0]
                        matched_content = hash_results['documents'][0]
                        
                        duplicate_objects.append({
                            'original': obj,
                            'similar': {
                                'id': matched_id,
                                'content': matched_content,
                                'hash': matched_metadata['hash'],
                                'bbox': json.loads(matched_metadata['bbox']),
                                'area': matched_metadata['area'],
                                'center': json.loads(matched_metadata['center']),
                                'type': matched_metadata['type'],
                                'object_id': matched_metadata['object_id']
                            },
                            'similarity': 1.0,
                            'reason': 'identical_hash_db'
                        })
                        print(f"ğŸ”„ DUPLICATE DETECTED (Hash-DB): {obj.get('content', 'Unknown')} (Sim: 1.000)")
                        found_duplicate = True
                        
                except Exception as e:
                    self.logger.debug(f"âš ï¸  DATABASE HASH QUERY FAILED: {e}")
                    # å¦‚æœç›´æ¥hashæŸ¥è¯¢å¤±è´¥ï¼Œå›é€€åˆ°æ–‡æœ¬æŸ¥è¯¢+hashæ¯”è¾ƒçš„æ–¹æ³•
                    try:
                        hash_results = self.object_collection.query(
                            query_texts=[obj.get('content', 'unknown')],
                            n_results=20,  # è·å–æ›´å¤šç»“æœä»¥ä¾¿hashæ¯”è¾ƒ
                            include=['metadatas', 'documents', 'distances']
                        )
                        
                        # æ£€æŸ¥è¿”å›ç»“æœä¸­æ˜¯å¦æœ‰ç›¸åŒçš„hash
                        for j in range(len(hash_results['ids'][0])):
                            metadata = hash_results['metadatas'][0][j]
                            stored_hash = metadata.get('hash', '')
                            
                            if stored_hash and stored_hash == obj['hash']:
                                duplicate_objects.append({
                                    'original': obj,
                                    'similar': {
                                        'id': hash_results['ids'][0][j],
                                        'content': hash_results['documents'][0][j],
                                        'hash': stored_hash,
                                        'bbox': json.loads(metadata['bbox']),
                                        'area': metadata['area'],
                                        'center': json.loads(metadata['center']),
                                        'type': metadata['type'],
                                        'object_id': metadata['object_id']
                                    },
                                    'similarity': 1.0,
                                    'reason': 'identical_hash_db'
                                })
                                print(f"ğŸ”„ DUPLICATE DETECTED (Hash-DB): {obj.get('content', 'Unknown')} (Sim: 1.000)")
                                found_duplicate = True
                                break
                    except Exception as e2:
                        self.logger.debug(f"âš ï¸  FALLBACK HASH QUERY ALSO FAILED: {e2}")
            
            if found_duplicate:
                continue
                
            # é˜¶æ®µ2: ä½¿ç”¨æ··åˆæŸ¥è¯¢è¿›è¡Œæ›´ç²¾ç¡®çš„ç›¸ä¼¼æ€§æ£€æµ‹ï¼ˆä»…åœ¨æ•°æ®åº“éç©ºæ—¶ï¼‰
            if not database_is_empty:
                similar_objects = self.query_collection_mixed(
                    obj, 
                    top_k=3,  # è·å–å‰3ä¸ªæœ€ç›¸ä¼¼çš„å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
                    text_weight=text_weight, 
                    image_weight=image_weight, 
                    bbox_weight=bbox_weight
                )

                if similar_objects:
                    # æ£€æŸ¥æ˜¯å¦æœ‰è¶…è¿‡é˜ˆå€¼çš„ç›¸ä¼¼å¯¹è±¡
                    best_match = similar_objects[0]
                    if best_match['similarity'] >= threshold:
                        # æ‰¾åˆ°ç›¸ä¼¼å¯¹è±¡ï¼Œæ ‡è®°ä¸ºé‡å¤
                        duplicate_objects.append({
                            'original': obj,
                            'similar': best_match,
                            'similarity': best_match['similarity'],
                            'reason': 'mixed_similarity'
                        })
                        print(f"ğŸ”„ DUPLICATE DETECTED (Mixed): {obj.get('content', 'Unknown')} (Sim: {best_match['similarity']:.3f})")
                        found_duplicate = True
            
            if not found_duplicate:
                # æ–°å¯¹è±¡
                new_objects.append(obj)
        
        return new_objects, duplicate_objects
    
    def update_object_with_vector_storage(self, objects: List[Dict], 
                                         text_weight: float = 0.3, image_weight: float = 0.5, 
                                         bbox_weight: float = 0.2, similarity_threshold: float = None) -> List[Dict]:
        """
        æ›´æ–°å¯¹è±¡å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ï¼Œä½¿ç”¨æ··åˆç›¸ä¼¼æ€§æ£€æµ‹
        
        Args:
            objects: å¯¹è±¡åˆ—è¡¨
            text_weight: æ–‡æœ¬ç›¸ä¼¼æ€§æƒé‡
            image_weight: å›¾åƒç›¸ä¼¼æ€§æƒé‡
            bbox_weight: è¾¹ç•Œæ¡†ç›¸ä¼¼æ€§æƒé‡
            similarity_threshold: ç›¸ä¼¼æ€§é˜ˆå€¼
            
        Returns:
            å¤„ç†åçš„å¯¹è±¡åˆ—è¡¨
        """
        if not objects:
            return []
        
        # ä½¿ç”¨æ··åˆç›¸ä¼¼æ€§è¿›è¡Œå»é‡å¤„ç†
        new_objects, duplicate_objects = self.deduplicate_objects(
            objects, 
            threshold=similarity_threshold, 
            text_weight=text_weight, 
            image_weight=image_weight, 
            bbox_weight=bbox_weight
        )
        
        # å­˜å‚¨æ–°å¯¹è±¡
        if new_objects:
            stored_ids = self.batch_store_objects(new_objects)
            for i, obj in enumerate(new_objects):
                if i < len(stored_ids):
                    obj['vector_id'] = stored_ids[i]
        
        # å¤„ç†é‡å¤å¯¹è±¡
        for dup in duplicate_objects:
            original = dup['original']
            similar = dup['similar']
            
            # æ›´æ–°åŸå¯¹è±¡çš„IDä¸ºç›¸ä¼¼å¯¹è±¡çš„ID
            original['id'] = similar.get('object_id', similar.get('id'))
            original['vector_id'] = similar.get('id')
            
            self.logger.debug(f"ğŸ”— OBJECT DEDUPLICATED: {original.get('content', 'Unknown')} -> {similar.get('id')} (Similarity: {similar.get('mixed_similarity', 0):.3f})")
        
        # åˆå¹¶ç»“æœ
        all_objects = new_objects + [dup['original'] for dup in duplicate_objects]
        
        self.logger.info(f"ğŸ“Š OBJECT PROCESSING COMPLETED: {len(new_objects)} new, {len(duplicate_objects)} duplicates")
        return all_objects
    
    def query_collection_by_text(self, content_query: str, top_k: int = 10) -> List[Dict]:
        """
        æ ¹æ®å†…å®¹æœç´¢å¯¹è±¡
        
        Args:
            content_query: å†…å®¹æŸ¥è¯¢å­—ç¬¦ä¸²
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            
        Returns:
            åŒ¹é…çš„å¯¹è±¡åˆ—è¡¨
        """
        try:
            # åˆ¤æ–­é€»è¾‘ä¸_init_chroma_dbä¿æŒä¸€è‡´
            if not self.embedding_type or self.embedding_type == "":
                # ç©ºå­—ç¬¦ä¸²æˆ–Noneï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬æŸ¥è¯¢
                results = self.object_collection.query(
                    query_texts=[content_query],
                    n_results=top_k,
                    include=['documents', 'metadatas', 'distances', 'embeddings']
                )
            elif self.embedding_type == "CLIP":
                # ä½¿ç”¨CLIPå¯¹æ–‡æœ¬è¿›è¡Œç¼–ç ï¼Œç¡®ä¿ä¸å›¾åƒå‘é‡ç»´åº¦ä¸€è‡´
                text_vector = self.encode_text(content_query)
                # ä½¿ç”¨å‘é‡æœç´¢è€Œä¸æ˜¯æ–‡æ¡£æœç´¢
                results = self.object_collection.query(
                    query_embeddings=[text_vector.tolist()],
                    n_results=top_k,
                    include=['documents', 'metadatas', 'distances', 'embeddings']
                )
            elif self.embedding_type in known_embedding_functions:
                # ä½¿ç”¨known_embedding_functionsä¸­çš„embeddingè¿›è¡Œæ–‡æœ¬æŸ¥è¯¢
                results = self.object_collection.query(
                    query_texts=[content_query],
                    n_results=top_k,
                    include=['documents', 'metadatas', 'distances', 'embeddings']
                )
            else:
                # ä¸æ”¯æŒçš„embedding_typeï¼Œä½¿ç”¨é»˜è®¤æ–‡æœ¬æŸ¥è¯¢
                results = self.object_collection.query(
                    query_texts=[content_query],
                    n_results=top_k,
                    include=['documents', 'metadatas', 'distances']
                )

            objects = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i]
                    embedding = results['embeddings'][0][i] if results.get('embeddings') else None
                    # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼šå¯¹äºä½™å¼¦è·ç¦»ï¼Œç›¸ä¼¼åº¦ = 1 - distance/2
                    # è¿™æ ·å¯ä»¥ç¡®ä¿ç›¸ä¼¼åº¦åœ¨ [0, 1] èŒƒå›´å†…ï¼Œ1è¡¨ç¤ºæœ€ç›¸ä¼¼ï¼Œ0è¡¨ç¤ºæœ€ä¸ç›¸ä¼¼
                    similarity = max(0, 1 - distance / 2)
                    objects.append({
                        'id': results['ids'][0][i],
                        'content': doc,
                        'bbox': json.loads(metadata['bbox']),
                        'area': metadata['area'],
                        'center': json.loads(metadata['center']),
                        'type': metadata['type'],
                        'object_id': metadata['object_id'],
                        'hash': metadata.get('hash', ''),
                        'distance': distance,
                        'similarity': similarity,
                        'embedding': embedding
                    })
            
            return objects

        except Exception as e:
            self.logger.error(f"å†…å®¹æœç´¢å¤±è´¥: {e}")
            return []

    def query_collection_by_image(self, query_image: np.ndarray, top_k: int = 10) -> List[Dict]:
        """
        æ ¹æ®å›¾åƒæœç´¢å¯¹è±¡
        
        Args:
            query_image: æŸ¥è¯¢å›¾åƒçš„numpyæ•°ç»„
            top_k: è¿”å›çš„æœ€å¤§ç»“æœæ•°
            
        Returns:
            åŒ¹é…çš„å¯¹è±¡åˆ—è¡¨
        """
        try:
            # åˆ¤æ–­é€»è¾‘ä¸_init_chroma_dbä¿æŒä¸€è‡´
            if not self.embedding_type or self.embedding_type == "":
                # é»˜è®¤embeddingä¸æ”¯æŒå›¾åƒæŸ¥è¯¢
                self.logger.warning("é»˜è®¤embeddingä¸æ”¯æŒå›¾åƒæŸ¥è¯¢")
                return []
            elif self.embedding_type == "CLIP":
                # ä½¿ç”¨CLIPå¯¹å›¾åƒè¿›è¡Œç¼–ç 
                image_vector = self.encode_image(query_image)
                # ä½¿ç”¨å‘é‡æœç´¢
                results = self.object_collection.query(
                    query_embeddings=[image_vector.tolist()],
                    n_results=top_k,
                    include=['documents', 'metadatas', 'distances', 'embeddings']
                )
            elif self.embedding_type in known_embedding_functions:
                # å¯¹äºæ”¯æŒå¤šæ¨¡æ€çš„embeddingå‡½æ•°ï¼ˆå¦‚open_clipï¼‰ï¼Œä½¿ç”¨å›¾åƒæŸ¥è¯¢
                if self.embedding_type == "open_clip":
                    # OpenCLIPEmbeddingFunctionæ”¯æŒå›¾åƒæŸ¥è¯¢
                    results = self.object_collection.query(
                        query_images=[query_image],
                        n_results=top_k,
                        include=['documents', 'metadatas', 'distances', 'embeddings']
                    )
                else:
                    # å…¶ä»–embeddingå‡½æ•°å¯èƒ½ä¸æ”¯æŒå›¾åƒæŸ¥è¯¢
                    self.logger.warning(f"Embeddingå‡½æ•° '{self.embedding_type}' å¯èƒ½ä¸æ”¯æŒå›¾åƒæŸ¥è¯¢")
                    return []
            else:
                # ä¸æ”¯æŒçš„embedding_type
                self.logger.warning(f"ä¸æ”¯æŒçš„embedding_type '{self.embedding_type}' è¿›è¡Œå›¾åƒæŸ¥è¯¢")
                return []

            objects = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i]
                    distance = results['distances'][0][i]
                    embedding = results['embeddings'][0][i] if results.get('embeddings') else None
                    # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼šå¯¹äºä½™å¼¦è·ç¦»ï¼Œç›¸ä¼¼åº¦ = 1 - distance/2
                    # è¿™æ ·å¯ä»¥ç¡®ä¿ç›¸ä¼¼åº¦åœ¨ [0, 1] èŒƒå›´å†…ï¼Œ1è¡¨ç¤ºæœ€ç›¸ä¼¼ï¼Œ0è¡¨ç¤ºæœ€ä¸ç›¸ä¼¼
                    similarity = max(0, 1 - distance / 2)
                    objects.append({
                        'id': results['ids'][0][i],
                        'content': doc,
                        'bbox': json.loads(metadata['bbox']),
                        'area': metadata['area'],
                        'center': json.loads(metadata['center']),
                        'type': metadata['type'],
                        'object_id': metadata['object_id'],
                        'hash': metadata.get('hash', ''),
                        'distance': distance,
                        'similarity': similarity,
                        'embedding': embedding
                    })
            
            return objects

        except Exception as e:
            self.logger.error(f"å›¾åƒæœç´¢å¤±è´¥: {e}")
            return []
    
    def get_collection_stats(self) -> Dict:
        """
        è·å–å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        try:
            count = self.object_collection.count()
            return {
                'total_objects': count,
                'game_name': self.game_name,
                'vector_dim': self.vector_dim,
                'db_path': self.vector_db_path
            }
        except Exception as e:
            self.logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def query_collection_mixed(self, query_obj: Dict, top_k: int = 10, 
                              text_weight: float = 0.4, image_weight: float = 0.4, 
                              bbox_weight: float = 0.2, bbox_scale: float = 1000.0) -> List[Dict]:
        """
        æ··åˆæŸ¥è¯¢æ–¹æ³•ï¼Œç»“åˆæ–‡æœ¬ç›¸ä¼¼åº¦ã€å›¾åƒç›¸ä¼¼åº¦å’Œbboxä½ç½®è·ç¦»
        ä¼˜åŒ–ç‰ˆæœ¬ï¼šè·å–æ›´å…¨é¢çš„å€™é€‰å¯¹è±¡é›†åˆï¼Œé¿å…é—æ¼ç›¸ä¼¼å¯¹è±¡
        
        Args:
            query_obj: æŸ¥è¯¢å¯¹è±¡ï¼ŒåŒ…å« content, cropped_image, bbox ç­‰å­—æ®µ
            top_k: è¿”å›ç»“æœæ•°é‡
            text_weight: æ–‡æœ¬ç›¸ä¼¼åº¦æƒé‡
            image_weight: å›¾åƒç›¸ä¼¼åº¦æƒé‡  
            bbox_weight: bboxè·ç¦»æƒé‡
            bbox_scale: bboxè·ç¦»å½’ä¸€åŒ–ç¼©æ”¾å› å­
            
        Returns:
            ç»¼åˆç›¸ä¼¼åº¦æ’åºçš„å¯¹è±¡åˆ—è¡¨
        """
        try:
            # ä¸ºquery_objç”Ÿæˆhashï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
            if 'hash' not in query_obj or not query_obj['hash']:
                query_obj['hash'] = self._generate_object_hash(query_obj)
            
            # è·å–æ•°æ®åº“ä¸­çš„æ€»å¯¹è±¡æ•°é‡
            collection_count = self.object_collection.count()
            if collection_count == 0:
                self.logger.info("ğŸ“­ VECTOR DATABASE IS EMPTY - No candidates available for similarity search")
                return []
            
            # åŠ¨æ€è°ƒæ•´å€™é€‰å¯¹è±¡æ•°é‡ï¼Œç¡®ä¿ä¸é—æ¼ç›¸ä¼¼å¯¹è±¡
            # å¯¹äºå»é‡åœºæ™¯ï¼Œæˆ‘ä»¬éœ€è¦æ›´å…¨é¢çš„å€™é€‰é›†åˆ
            if top_k == 1:  # å»é‡åœºæ™¯ï¼Œè·å–æ›´å¤šå€™é€‰å¯¹è±¡
                candidate_k = min(collection_count, max(500, collection_count // 2))
            else:  # å¸¸è§„æŸ¥è¯¢åœºæ™¯
                candidate_k = min(collection_count, max(top_k * 10, 100))
            
            # è·å–å€™é€‰å¯¹è±¡é›†åˆ - ä½¿ç”¨å¤šç§ç­–ç•¥ç¡®ä¿è¦†ç›–é¢
            all_candidates = {}
            
            # ç­–ç•¥1: æ–‡æœ¬æŸ¥è¯¢è·å–å€™é€‰å¯¹è±¡
            if 'content' in query_obj and query_obj['content']:
                text_results = self.query_collection_by_text(query_obj['content'], candidate_k)
                for result in text_results:
                    all_candidates[result['id']] = result
            
            # ç­–ç•¥2: å›¾åƒæŸ¥è¯¢è·å–å€™é€‰å¯¹è±¡ï¼ˆä¸æ–‡æœ¬æŸ¥è¯¢å¹¶è¡Œï¼Œä¸æ˜¯è¡¥å……ï¼‰
            if 'image' in query_obj and query_obj['image'] is not None:
                image_results = self.query_collection_by_image(query_obj['image'], candidate_k)
                for result in image_results:
                    if result['id'] not in all_candidates:
                        all_candidates[result['id']] = result
            
            # ç­–ç•¥3: å¦‚æœå€™é€‰å¯¹è±¡ä»ç„¶ä¸è¶³ï¼Œè·å–æ‰€æœ‰å¯¹è±¡è¿›è¡Œå…¨é¢æ¯”è¾ƒ
            if len(all_candidates) < candidate_k:
                try:
                    remaining_needed = candidate_k - len(all_candidates)
                    results = self.object_collection.query(
                        query_texts=["*"],  # é€šç”¨æŸ¥è¯¢
                        n_results=min(remaining_needed, collection_count),
                        include=['metadatas', 'documents', 'distances', 'embeddings']
                    )
                    
                    for i in range(len(results['ids'][0])):
                        obj_id = results['ids'][0][i]
                        if obj_id not in all_candidates:  # é¿å…é‡å¤
                            metadata = results['metadatas'][0][i]
                            doc = results['documents'][0][i]
                            distance = results['distances'][0][i]
                            embedding = results['embeddings'][0][i] if results.get('embeddings') else None
                            similarity = max(0, 1 - distance / 2)
                            
                            all_candidates[obj_id] = {
                                'id': obj_id,
                                'content': doc,
                                'bbox': json.loads(metadata['bbox']),
                                'area': metadata['area'],
                                'center': json.loads(metadata['center']),
                                'type': metadata['type'],
                                'object_id': metadata['object_id'],
                                'hash': metadata.get('hash', ''),
                                'distance': distance,
                                'similarity': similarity,
                                'embedding': embedding
                            }
                except Exception as e:
                    self.logger.warning(f"âš ï¸  FAILED TO GET ADDITIONAL CANDIDATES: {e}")
            
            # ä¸ºæ‰€æœ‰å€™é€‰å¯¹è±¡è®¡ç®—å®Œæ•´çš„æ–‡æœ¬å’Œå›¾åƒç›¸ä¼¼åº¦
            query_text_embedding = None
            
            # å‡†å¤‡æŸ¥è¯¢åµŒå…¥
            if 'content' in query_obj and query_obj['content']:
                query_text_embedding = self.encode_text(query_obj['content'])
            
            # ä¸ºæ¯ä¸ªå€™é€‰å¯¹è±¡è®¡ç®—ç›¸ä¼¼åº¦
            for obj_id, candidate in all_candidates.items():
                text_similarity = 0.0
                image_similarity = 0.0
                
                # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
                if query_text_embedding is not None and candidate.get('content'):
                    try:
                        candidate_text_embedding = self.encode_text(candidate['content'])
                        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                        text_cosine_sim = np.dot(query_text_embedding, candidate_text_embedding) / (
                            np.linalg.norm(query_text_embedding) * np.linalg.norm(candidate_text_embedding)
                        )
                        text_similarity = max(0, (text_cosine_sim + 1) / 2)  # è½¬æ¢åˆ°[0,1]èŒƒå›´
                    except Exception as e:
                        self.logger.debug(f"âš ï¸  TEXT SIMILARITY CALCULATION FAILED: {e}")
                
                # ä¼˜åŒ–çš„å›¾åƒç›¸ä¼¼åº¦è®¡ç®— - ä½¿ç”¨hashæ¯”è¾ƒå’Œæ›´ç²¾ç¡®çš„é˜ˆå€¼
                if 'hash' in query_obj and query_obj['hash'] and 'hash' in candidate and candidate['hash']:
                    try:
                        query_hash = query_obj['hash']
                        candidate_hash = candidate['hash']
                        
                        # å¦‚æœhashå®Œå…¨ç›¸åŒï¼Œç›¸ä¼¼åº¦ä¸º1.0
                        if query_hash == candidate_hash:
                            image_similarity = 1.0
                        else:
                            # è®¡ç®—hashçš„æ±‰æ˜è·ç¦»ç›¸ä¼¼åº¦
                            try:
                                query_bin = bin(int(query_hash, 16))[2:].zfill(64)  # è½¬ä¸º64ä½äºŒè¿›åˆ¶
                                candidate_bin = bin(int(candidate_hash, 16))[2:].zfill(64)
                                
                                # è®¡ç®—æ±‰æ˜è·ç¦»
                                hamming_distance = sum(c1 != c2 for c1, c2 in zip(query_bin, candidate_bin))
                                # è½¬æ¢ä¸ºç›¸ä¼¼åº¦ï¼Œä½¿ç”¨æ›´æ•æ„Ÿçš„é˜ˆå€¼
                                max_distance = 64.0
                                # å¯¹äºå»é‡åœºæ™¯ï¼Œæˆ‘ä»¬éœ€è¦æ›´ä¸¥æ ¼çš„ç›¸ä¼¼åº¦åˆ¤æ–­
                                if hamming_distance <= 8:  # å…è®¸å°‘é‡å·®å¼‚
                                    image_similarity = 1.0 - (hamming_distance / max_distance) * 0.5
                                else:
                                    image_similarity = max(0, 1 - hamming_distance / max_distance)
                            except ValueError:
                                # å¦‚æœhashæ ¼å¼ä¸æ­£ç¡®ï¼Œä½¿ç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
                                common_chars = sum(c1 == c2 for c1, c2 in zip(query_hash, candidate_hash))
                                image_similarity = common_chars / max(len(query_hash), len(candidate_hash))
                    except Exception as e:
                        self.logger.debug(f"âš ï¸  IMAGE HASH SIMILARITY CALCULATION FAILED: {e}")
                        image_similarity = 0.0
                else:
                    image_similarity = 0.0
                
                candidate['text_similarity'] = text_similarity
                candidate['image_similarity'] = image_similarity
            
            # è®¡ç®—bboxè·ç¦»ç›¸ä¼¼åº¦
            query_bbox = query_obj.get('bbox', None)
            if query_bbox:
                query_center = query_obj.get('center', None)
                
                for obj_id, candidate in all_candidates.items():
                    candidate_center = candidate.get('center', None)
                    
                    # è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
                    distance = np.sqrt((query_center[0] - candidate_center[0])**2 + 
                                     (query_center[1] - candidate_center[1])**2)
                    
                    # å°†è·ç¦»è½¬æ¢ä¸ºç›¸ä¼¼åº¦ (è·ç¦»è¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜)
                    bbox_similarity = max(0, 1 - distance / bbox_scale)
                    candidate['bbox_similarity'] = bbox_similarity
            else:
                # å¦‚æœæ²¡æœ‰bboxä¿¡æ¯ï¼Œbboxç›¸ä¼¼åº¦è®¾ä¸º0.5ï¼ˆä¸­æ€§å€¼ï¼‰
                for candidate in all_candidates.values():
                    candidate['bbox_similarity'] = 0.5
            
            # è®¡ç®—ç»¼åˆç›¸ä¼¼åº¦
            for candidate in all_candidates.values():
                # å½’ä¸€åŒ–æƒé‡
                total_weight = text_weight + image_weight + bbox_weight
                norm_text_weight = text_weight / total_weight
                norm_image_weight = image_weight / total_weight
                norm_bbox_weight = bbox_weight / total_weight
                
                # è®¡ç®—åŠ æƒç»¼åˆç›¸ä¼¼åº¦
                mixed_similarity = (candidate['text_similarity'] * norm_text_weight + 
                                  candidate['image_similarity'] * norm_image_weight + 
                                  candidate['bbox_similarity'] * norm_bbox_weight)
                
                candidate['mixed_similarity'] = mixed_similarity
                candidate['similarity'] = mixed_similarity  # æ›´æ–°ä¸»ç›¸ä¼¼åº¦å­—æ®µ
            
            # æŒ‰ç»¼åˆç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›top_kç»“æœ
            sorted_results = sorted(all_candidates.values(), 
                                  key=lambda x: x['mixed_similarity'], reverse=True)
            
            return sorted_results[:top_k]
            
        except Exception as e:
            self.logger.error(f"âŒ MIXED QUERY FAILED: {e}")
            return []
    
    def clear_database(self):
        """æ¸…ç©ºå‘é‡æ•°æ®åº“"""
        try:
            # åˆ é™¤collection
            self.client.delete_collection("ui_objects")
            
            # é‡æ–°åˆ›å»º
            # self.object_collection = self.client.create_collection(
            #     name="ui_objects",
            #     metadata={"hnsw:space": "cosine"}
            # )
            
            self.logger.info("å‘é‡æ•°æ®åº“å·²æ¸…ç©º")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç©ºæ•°æ®åº“å¤±è´¥: {e}")